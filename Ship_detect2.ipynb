{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.ops import box_iou\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = sorted([img for img in os.listdir(os.path.join(root, \"images\")) if os.path.isfile(os.path.join(root, \"annotations\", img.replace('.bmp', '.xml')))])\n",
    "        self.annotations = sorted([ann for ann in os.listdir(os.path.join(root, \"annotations\")) if os.path.isfile(os.path.join(root, \"images\", ann.replace('.xml', '.bmp')))])\n",
    "\n",
    "        assert len(self.imgs) == len(self.annotations), \"Mismatch between number of images and annotations\"\n",
    "\n",
    "        self.wordname_50 = ['Other Ship', 'Other Warship', 'Submarine', 'Other Aircraft Carrier', 'Enterprise', \n",
    "                            'Nimitz', 'Midway', 'Ticonderoga', 'Other Destroyer', 'Atago DD', 'Arleigh Burke DD', \n",
    "                            'Hatsuyuki DD', 'Hyuga DD', 'Asagiri DD', 'Other Frigate', 'Perry FF', 'Patrol', \n",
    "                            'Other Landing', 'YuTing LL', 'YuDeng LL', 'YuDao LL', 'YuZhao LL', 'Austin LL', \n",
    "                            'Osumi LL', 'Wasp LL', 'LSD 41 LL', 'LHA LL', 'Commander', 'Other Auxiliary Ship', \n",
    "                            'Medical Ship', 'Test Ship', 'Training Ship', 'AOE', 'Masyuu AS', 'Sanantonio AS', 'EPF', \n",
    "                            'Other Merchant', 'Container Ship', 'RoRo', 'Cargo', 'Barge', 'Tugboat', 'Ferry', 'Yacht', \n",
    "                            'Sailboat', 'Fishing Vessel', 'Oil Tanker', 'Hovercraft', 'Motorboat', 'Dock']\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        ann_path = os.path.join(self.root, \"annotations\", self.annotations[idx])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in root.findall(\"object\"):\n",
    "            bndbox = obj.find(\"bndbox\")\n",
    "            xmin = int(bndbox.find(\"xmin\").text)\n",
    "            ymin = int(bndbox.find(\"ymin\").text)\n",
    "            xmax = int(bndbox.find(\"xmax\").text)\n",
    "            ymax = int(bndbox.find(\"ymax\").text)\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            label_name = obj.find(\"name\").text\n",
    "            label = self.wordname_50.index(label_name) + 1  # +1 to make background class 0\n",
    "            labels.append(label)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = [T.ToTensor()]\n",
    "    if train:\n",
    "        transforms.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared CUDA memory cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(params, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m    114\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m clear_memory()  \u001b[38;5;66;03m# Clear memory after training\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 63\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs, data_loader, model, optimizer, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m     62\u001b[0m     loss_dict \u001b[38;5;241m=\u001b[39m model(images, targets)\n\u001b[0;32m---> 63\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m \u001b[43mloss_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m())\n\u001b[1;32m     65\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(losses)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Cleared CUDA memory cache\")\n",
    "\n",
    "def calculate_metrics(pred_boxes, pred_labels, pred_scores, true_boxes, true_labels, iou_threshold=0.5):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    if len(pred_boxes) == 0 and len(true_boxes) == 0:\n",
    "        return 1, 1, 1  # precision, recall, F1 score\n",
    "    if len(pred_boxes) == 0:\n",
    "        return 0, 0, 0\n",
    "    if len(true_boxes) == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    ious = box_iou(torch.tensor(pred_boxes), torch.tensor(true_boxes))\n",
    "    for i, pred in enumerate(pred_boxes):\n",
    "        if pred_labels[i] in true_labels:\n",
    "            max_iou = torch.max(ious[i]).item()\n",
    "            if max_iou > iou_threshold:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    for j, true in enumerate(true_boxes):\n",
    "        if true_labels[j] in pred_labels:\n",
    "            max_iou = torch.max(ious[:, j]).item()\n",
    "            if max_iou <= iou_threshold:\n",
    "                false_negatives += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def train_model(num_epochs, data_loader, model, optimizer, device):\n",
    "    model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_precision = 0\n",
    "        epoch_recall = 0\n",
    "        epoch_f1 = 0\n",
    "\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += losses.item()\n",
    "\n",
    "            # Calculate metrics\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                outputs = model(images)\n",
    "                for i, output in enumerate(outputs):\n",
    "                    pred_boxes = output['boxes'].cpu().numpy()\n",
    "                    pred_labels = output['labels'].cpu().numpy()\n",
    "                    pred_scores = output['scores'].cpu().numpy()\n",
    "                    \n",
    "                    true_boxes = targets[i]['boxes'].cpu().numpy()\n",
    "                    true_labels = targets[i]['labels'].cpu().numpy()\n",
    "                    \n",
    "                    precision, recall, f1_score = calculate_metrics(pred_boxes, pred_labels, pred_scores, true_boxes, true_labels)\n",
    "                    \n",
    "                    epoch_precision += precision\n",
    "                    epoch_recall += recall\n",
    "                    epoch_f1 += f1_score\n",
    "\n",
    "        epoch_loss /= len(data_loader)\n",
    "        epoch_precision /= len(data_loader)\n",
    "        epoch_recall /= len(data_loader)\n",
    "        epoch_f1 /= len(data_loader)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {epoch_loss:.4f}, Precision: {epoch_precision:.4f}, Recall: {epoch_recall:.4f}, F1 Score: {epoch_f1:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clear_memory()  # Clear memory before starting the training\n",
    "\n",
    "    dataset = ShipDataset(root=\"ShipRSImageNet_V1/Dataset/\", transforms=get_transform(train=True))\n",
    "    data_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    weights = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    num_classes = 51  # 50 ship classes + background\n",
    "    in_features = weights.roi_heads.box_predictor.cls_score.in_features\n",
    "    weights.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    model = weights.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    num_epochs = 10\n",
    "    train_model(num_epochs, data_loader, model, optimizer, device)\n",
    "\n",
    "    clear_memory()  # Clear memory after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import ssd300_vgg16, SSD300_VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Cleared CUDA memory cache\")\n",
    "\n",
    "def train_model(num_epochs, data_loader, model, optimizer, device):\n",
    "    model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += losses.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {epoch_loss/len(data_loader)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clear_memory()  # Clear memory before starting the training\n",
    "\n",
    "    dataset = ShipDataset(root=\"ShipRSImageNet_V1/Dataset/\", transforms=get_transform(train=True))\n",
    "    data_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    weights = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    num_classes = 51  # 50 ship classes + background\n",
    "    in_features = weights.roi_heads.box_predictor.cls_score.in_features\n",
    "    weights.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    model = weights.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    num_epochs = 10\n",
    "    train_model(num_epochs, data_loader, model, optimizer, device)\n",
    "\n",
    "    clear_memory()  # Clear memory after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./checkpoint/ship_detect_rsnn_10epochs_8batch.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShipDataset(root=\"ShipRSImageNet_V1/Dataset/\", transforms=get_transform(train=True))\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "weights = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 51  # 50 ship classes + background\n",
    "in_features = weights.roi_heads.box_predictor.cls_score.in_features\n",
    "weights.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "model = weights.to(device)\n",
    "model.load_state_dict(torch.load(\"./checkpoint/ship_detect_rsnn_15epochs.h5\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def predict_image(model, image_path, device, confidence_threshold=0.5):\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "\n",
    "    # Process the predictions\n",
    "    pred_boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "    pred_labels = predictions[0]['labels'].cpu().numpy()\n",
    "    pred_scores = predictions[0]['scores'].cpu().numpy()\n",
    "\n",
    "    # Filter out low-confidence detections\n",
    "    high_conf_indices = pred_scores > confidence_threshold\n",
    "    pred_boxes = pred_boxes[high_conf_indices]\n",
    "    pred_labels = pred_labels[high_conf_indices]\n",
    "    pred_scores = pred_scores[high_conf_indices]\n",
    "\n",
    "    return pred_boxes, pred_labels, pred_scores\n",
    "\n",
    "def display_predictions(image_path, boxes, labels, scores, class_names):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        width, height = xmax - xmin, ymax - ymin\n",
    "        edgecolor = 'r'\n",
    "        ax.add_patch(patches.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor=edgecolor, facecolor='none'))\n",
    "        ax.text(xmin, ymin, f\"{class_names[label-1]}: {score:.2f}\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"test/DIOR/JPEGImages-test_has_ships/12908.jpg\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Assuming `model`, `device`, and `dataset.wordname_50` are already defined\n",
    "model.to(device)\n",
    "pred_boxes, pred_labels, pred_scores = predict_image(model, image_path, device, confidence_threshold=0.3)\n",
    "\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img)\n",
    "\n",
    "if len(pred_boxes) > 0:\n",
    "    display_predictions(image_path, pred_boxes, pred_labels, pred_scores, dataset.wordname_50)\n",
    "else:\n",
    "    print(\"No objects detected with the specified confidence threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "with open('./test/shipsnet.json') as data_file:\n",
    "    dataset = json.load(data_file)\n",
    "Shipsnet= pd.DataFrame(dataset)\n",
    "print(Shipsnet.head())\n",
    "print('')    \n",
    "x = np.array(dataset['data']).astype('uint8')\n",
    "y = np.array(dataset['labels']).astype('uint8')\n",
    "def describeData(a,b):\n",
    "    print('Total number of images: {}'.format(len(a)))\n",
    "    print('Number of NoShip Images: {}'.format(np.sum(b==0)))\n",
    "    print('Number of Ship Images: {}'.format(np.sum(b==1)))\n",
    "    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n",
    "    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\n",
    "describeData(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
